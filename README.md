# Forced Alignment using Montreal Forced Aligner (MFA)

## Overview
This repository implements an end-to-end forced alignment pipeline using the Montreal Forced Aligner (MFA). The goal is to automatically align speech audio with its corresponding transcription at word and phoneme levels.

## Dataset
The dataset contains six English audio files (.wav), each paired with a corresponding transcript (.txt). Each audio file represents a single utterance spoken by one speaker. Only the provided dataset was used for all experiments.

## Environment Setup
- Operating System: Windows with WSL (Ubuntu)
- Python Environment: Conda
- Tool: Montreal Forced Aligner (MFA)
- Acoustic Model: english_us_arpa
- Dictionary: Generated using MFA G2P

## Data Preparation
- Audio and transcript files are organized under `data/speaker1/`
- Transcript normalization steps:
  - Conversion to uppercase
  - Removal of punctuation and special characters
  - Number-to-word conversion
- Acronym expansion was intentionally excluded

## OOV Handling
Initial validation revealed out-of-vocabulary (OOV) words. These were resolved using MFA’s English ARPA G2P model, resulting in zero OOV words before forced alignment.

## Commands Used

### Validation
```bash
mfa validate data g2p.dict english_us_arpa
```

### Forced Alignment
```bash
mfa align data g2p.dict english_us_arpa output
```

## Output
The `output/` directory contains TextGrid files generated by MFA, providing word-level and phoneme-level alignments for each audio file.

## Analysis
The generated TextGrid files were inspected using Praat. Word boundaries aligned well with regions of high acoustic energy, and phoneme boundaries captured detailed acoustic transitions. Minor timing offsets were observed, which are expected in automatic forced alignment systems.

## Files in Repository
- `normalize_no_acronyms.py` – Transcript normalization script
- `g2p.dict` – Generated pronunciation dictionary
- `output/` – Alignment results (TextGrid files)
- `MFA_Forced_Alignment_Report.docx` – Final report
